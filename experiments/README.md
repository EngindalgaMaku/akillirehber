# ğŸ§ª Deney Tekrarlama Betikleri

Bu dizin, AkÄ±llÄ±Rehber makalesinde sunulan deneysel sonuÃ§larÄ±n tekrarlanabilmesi iÃ§in gerekli betikleri iÃ§ermektedir.

## Ã–n KoÅŸullar

1. AkÄ±llÄ±Rehber sistemi Ã§alÄ±ÅŸÄ±r durumda olmalÄ±dÄ±r (Docker Compose ile):
   ```bash
   docker-compose up -d
   ```

2. Python baÄŸÄ±mlÄ±lÄ±klarÄ±:
   ```bash
   pip install -r requirements.txt
   ```

3. `.env` dosyasÄ±nda API anahtarlarÄ± tanÄ±mlÄ± olmalÄ±dÄ±r:
   ```
   OPENROUTER_API_KEY=sk-or-...
   SECRET_KEY=...
   ```

4. Bloom veri seti yÃ¼klenmiÅŸ olmalÄ±dÄ±r:
   - Veri seti: https://github.com/EngindalgaMaku/Bilisim-Teknolojileri-Bloom-Dataset

## Betikler

### 1. RAGAS DeÄŸerlendirmesi (`run_ragas_evaluation.py`)

Bloom veri setindeki 100 soru Ã¼zerinde RAGAS metriklerini hesaplar:
- Faithfulness (Sadakat)
- Answer Relevancy (YanÄ±t Ä°lgililiÄŸi)
- Context Precision (BaÄŸlam Hassasiyeti)
- Context Recall (BaÄŸlam DuyarlÄ±lÄ±ÄŸÄ±)
- Answer Correctness (YanÄ±t DoÄŸruluÄŸu)

```bash
python run_ragas_evaluation.py --course-id 1 --test-set-id 1
```

### 2. ROUGE ve BERTScore DeÄŸerlendirmesi (`run_rouge_bertscore.py`)

AynÄ± veri seti Ã¼zerinde metin benzerliÄŸi metriklerini hesaplar:
- ROUGE-1, ROUGE-2, ROUGE-L
- BERTScore (Precision, Recall, F1)

```bash
python run_rouge_bertscore.py --course-id 1 --test-set-id 1
```

### 3. RAG vs Direct LLM KarÅŸÄ±laÅŸtÄ±rmasÄ± (`run_rag_vs_directllm.py`)

RAG tabanlÄ± yanÄ±tlar ile yalÄ±n LLM yanÄ±tlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r:

```bash
python run_rag_vs_directllm.py --course-id 1 --test-set-id 1
```

### 4. PII Filtreleme Performans DeÄŸerlendirmesi (`run_pii_evaluation.py`)

KVKK uyumlu kiÅŸisel bilgi filtreleme katmanÄ±nÄ±n precision/recall analizini yapar:
- Katman 1 (Regex): TC kimlik, telefon, e-posta, IBAN, kredi kartÄ±, pasaport
- Katman 2 (Few-Shot Embedding): Åifre, adres, doÄŸum tarihi gibi belirsiz durumlar

```bash
# Sadece regex katmanÄ± (offline, API gerektirmez)
python run_pii_evaluation.py

# Tam test (regex + embedding, API gerektirir, PII filtresi aÃ§Ä±k olmalÄ±)
python run_pii_evaluation.py --with-api --course-id 1
```

### 5. TÃ¼m Deneyleri Ã‡alÄ±ÅŸtÄ±r (`run_all_experiments.py`)

YukarÄ±daki Ã¼Ã§ deneyi sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±r ve sonuÃ§larÄ± `results/` dizinine kaydeder:

```bash
python run_all_experiments.py --course-id 1 --test-set-id 1
```

## Ã‡Ä±ktÄ±lar

SonuÃ§lar `results/` dizinine JSON ve CSV formatÄ±nda kaydedilir:
- `results/ragas_results.json` â€” RAGAS metrikleri
- `results/rouge_bertscore_results.json` â€” ROUGE ve BERTScore metrikleri
- `results/rag_vs_directllm_results.json` â€” KarÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ±
- `results/pii_evaluation_results.json` â€” PII filtreleme precision/recall
- `results/summary.csv` â€” TÃ¼m metriklerin Ã¶zet tablosu

## Deney KonfigÃ¼rasyonu

VarsayÄ±lan konfigÃ¼rasyon `experiment_config.json` dosyasÄ±nda tanÄ±mlÄ±dÄ±r. Ã–zelleÅŸtirmek iÃ§in bu dosyayÄ± dÃ¼zenleyebilirsiniz.
